{"title":"Yikun","description":null,"language":null,"link":"http://yikun.github.io","pubDate":"Wed, 16 Aug 2017 12:50:32 GMT","lastBuildDate":"Tue, 05 Sep 2017 15:57:00 GMT","generator":"hexo-generator-json-feed","webMaster":"Yikun","items":[{"title":"[译] Simpler Road to Cinder Active-Active","link":"http://yikun.github.io/2017/08/16/译-Simpler-Road-to-Cinder-Active-Active/","description":"译注：本篇文章为作者介绍Cinder AA方案的文章，作者是gorka，是实现cinder AA BP的core，文章介绍了这哥们实现AA时的记录，算是对方案的一种解释以及设计思路的总结，核心思想为以下几点： 每个volume node都增加一个cluster的配置项，作为集群，标记这个节点属于某个集群； 通过cluster@backend作为消息队列的topic，并且启动cluster@backend的服务； scheduler进行调度时，投递到某个合适的集群，集群中的某个后端进行消费； 消费时，将操作记录在worker中，用来标记这个资源由某个worker来操作，这样当发生异常时，可以确保仅有某个worker进行cleanup的操作。 原文链接：Simpler Road to Cinder Active-Active 上一周，我发了一篇文，来介绍Cinder AA配置方案，可是，让我很受伤的是，觉得那个方案有点太复杂了，所以呢，这一波又搞了个简单的方案。 变更初心我确实很喜欢我上周发布的允许Cinder使用AA HA配置的方案，不过想起来，确实有些复杂了，没必要为了一点点的益处，就把那么复杂的机制加到组件里。（比如恢复排队任务） 这个方案从决绝到接受，没有花费我太多时间，毕竟上个方案确实留下了一些复杂，所以必须要一个更简单的方案，所以呢，我相信这一波方案是一个合理的选择。 我准备用上篇博客同样的格式，来对同样的问题给出解决方案，这样对于读上篇博客的人来说看起来比较熟悉。尽管在这我没有太多的时间来搞patch和流程图，我会在Cinder Midcycle Sprint的时候把他们准备好。 任务调度我们应该如何在一个cluster中的不同node去做任务调度呢？ 在任务调度的时候，我们仍然不想让API或者Scheduler节点太多的考虑有多少volume节点或者说操心具体集群中哪一个节点时可用的。我们将还是用原来的方法——主题队列，唯一的不同在于，我们改变了这些队列的主题，从原来的host@backend变为了cluster@backend。 cluster将成为一个新的配置——同一集群中的所有节点都使用相同的配置。如果没有配置的话，默认会使用host作为值。同时，在cinder部署时，任何一个节点的host应该是唯一的。 将host的值作为cluster的默认值有很多好处，非AA配置可以将服务视为之前的host@backend，如果一个节点或者说原来的主备配置的节点，想要变为AA模式，只需要把后面加进来的节点，把cluster都改成和第一个host的值就行了，这样就可以保证服务可以不挂掉。这样做虽然不是那么干脆利落，但这个可以帮助管理员在可以down机的时候，再去做整改。 清理资源为了进行清理，我们需要在所有的资源表（如卷、备份、快照等）增加一个新的字段。我们称其为“worker”，它可以有3个不同的值： 空值：资源无节点操作 cluster@backend：资源正在排队等待worker操作 host@backned：资源已经被一个worker选择 或许，我们不需要cluester@backend这个值也可以工作的很好，不过我还是觉得应该记录现在处于什么状态了我们也用到了“previous_status”这个字段，就像我们对in-used卷做备份操作那样。对于已经存在的资源，正常的工作流程像下面一样： API接受请求，在RPC调用投递到指定的volume topic队列之前，需要修改status和pre_vious_status以及worker字段来匹配资源的host字段（cluster@backend） 当volume节点接受这个job，将会在DB把worker字段更改为host@backend 当完成这个操作后，将置空worker字段，然后将status恢复为previous_status字段。 看起来不错，但我们如何去做清理呢？其实和目前的实现差不多，仅有一点小小的改动。当节点启动时，搜寻所有worker为自己所属的host@backend的资源，然后对这个worker filed做compare-and-swap置空，确保没有其他节点来操作这个资源，也保证仅做了我们需要的改动。然后对于一些资源的操作（比如deleting）我们设置worker字段为cluser@backend，然后RPC调用。这样，我们在所有集群的节点做了分发。还是看起来不错吧？但是我们如何处理那些没有恢复如初，或者那些无法failover的备节点呢？这个case会通过Scheduler来处理，我们会在后面介绍。另外的选择是，我们不用在每个资源表里都增加一个新的字段，我们可以为资源创建一个特殊的表来记录work。如果我们使用了这个方案，我们需在wokrer里面存储resource id，来记录这个ID那个资源的。这个方案修改量比较小，我们想知道谁操作某个特定的资源有点困难，但我们只需要访问一个表，就可以很简单的获取所有某个节点操作的所有资源。 API Nodes接下来，我们需要移除race，就像我上篇文章介绍的那样。但是我们也需要额外的变化依赖于我们如何处理资源的互斥。 Volume Nodes我并不想再赘述我们如何如何的需要改变目前的本地锁机制，这已经在上篇文章介绍过了。在社区有一个分歧，一部分人认为应该使用DLM解决资源锁，另一部分人认为应该避免让云管理员去部署和配置更多的软件（比如，redis、zookeeper等）我个人理解是使用DLM去实现AA是一个中间方案，直到我们完全的实现AA。因为我们使用Tooz可以很轻松的实现，这也是为什么我更偏向这个选择。我们可以先快速实现它，然后后面的版本再把锁从Manager和driver中移除。 附注一点，一些driver可以移除锁只要我们移除了API竞争，然后添加一些缺失的锁。DLM这种方案，仅会影响AA的部署，而对初始的没有其他影响。 但是，通常思考另一种选择是好事情，这仅仅是我喜欢的而不是说是最好的，那么另外一种选择就是使用资源的状态。 Service state reporting为了探测节点有没有挂掉，也为了对那些还没有就位的节点（或者还得一段时间才能恢复的节点）进行清理，每一个集群节点都会进行report，分别占用DB不同的行。 我们可以用现在的host字段，上报时使用“cluster@backend@hostend”或者使用一个新的字段backend或者cluster里面包含cluster@backend段，然后host还是放在host字段不变。 其实，这一点倒不那么重要，这只是实现细节而已。在任何一个scheduler节点，都会有个周期任务检查数据库的内容，然后创建创建一个key为cluster@backend的字典，并存在value里，如果他是不同节点的信息以及是否我们对这个节点完成了清理。节点起来后，将会把cleanup_done设置为False。 如果cluster中的任何一个节点up，那么这个服务就up。 对于那些已经down的节点，我们将进行cleanup操作，就像我们在voluem node启动时做的那样，然后把cleanup_done字段设置为True。所以我们在下一次这个task启动时不会检查这个任务。 如果多个scheduler尝试同时对一个node进行清理，或者scheduler和之前的备节点现在active了，并且同时对资源进行修复。由于我们在数据库做的是使用compare andswap的原子变更，跳过失败即可，确保只有一个完成资源的清理。 Capabilities reporting我们上报容量使用cluser@backend作为host即可，我们不需要作任何变动。 Prevent data corruption与上周的方案不同，组织数据出错更简单，这也是这个方案简单的一个主要原因。 我们不需要关心我们是否和后端失去连接，也不用关心我们与消息队列失去连接 如果我们与数据库失去连接我们需要停掉一切正在进行的操作，最简单的就是在心跳周期方案做这个事情。我们可以停掉backend的一切操作。 当我们使用DLM，我们应该检查连接，连接丢失要停掉所有操作，并且停止发送心跳，因为我们做不了任何事。","pubDate":"Wed, 16 Aug 2017 12:50:32 GMT","guid":"http://yikun.github.io/2017/08/16/译-Simpler-Road-to-Cinder-Active-Active/","category":"Cinder"},{"title":"一次有关OpenStack请求的性能问题分析","link":"http://yikun.github.io/2016/07/22/一次有关OpenStack请求的性能问题分析/","description":"0. 背景介绍目前OpenStack对外提供的北向接口是以REST接口提供的，也就是说通过HTTP（HTTPS）接口进行请求，进行虚拟机或者卷等相关的操作。OpenStack提供I层基本的能力，比如创建、查询、删除虚拟机或者卷等操作，以OpenStack作为平台，对上提供用户接口，对下操作下层Driver完成对设备的操作，其大致的架构基本如下所示： 整个OpenStack提供的接口也都是无状态的，对外接口也非常简单，例如获取卷的详情可以通过volumes的接口，最终可以得到卷的详情信息： 一般调用这些接口的上层主要是一些编排性或者提高用户体验的应用，达到“点一个按钮”完成对资源创建或者查询的应用。 1. 问题出现问题的现象是，上层对资源进行操作、查询的时候非常慢，而实际在上层应用的服务器节点通过curl命令去调OpenStack接口的时候，发现整体时延均在秒级以上，甚至一个非常简单的卷查询指令也耗费了1秒以上的时间，而通过ping指令去测OpenStack响应时，保持在200ms左右，那么中间的时间耗在了哪？ 2. 定位结论好吧，我承认这篇文章写了一年了。。。不装逼了，直接说结论吧。当时遇到一个非常奇葩的问题，就是任何请求都耗时非常久，最后发现原来是https搞得鬼。 对于正常的http请求来说，请求本身耗时大致是一个RTT（TCP的三次握手），而对于https，中间增加了SSL握手的时间，大概算下来是3倍+的时延。 重点呢就是想记录一下这个指令：1curl -w \"TCP handshake: %&#123;time_connect&#125;, SSL handshake: %&#123;time_appconnect&#125;\\n\" -so /dev/null https://www.baidu.com 可以得到类似的结果，也告诉了用户大致请求中间的耗时花费在哪了，结果就像这样： TCP handshake: 0.049, SSL handshake: 0.163 好了，就酱紫，底下参考链接是当时看的一些资料。 参考链接SSL handshake latency and HTTPS optimizations.大型网站的 HTTPS 实践（2）：HTTPS 对性能的影响HTTPS 要比 HTTP 多用多少服务器资源？HTTPS连接的前几毫秒发生了什么图解SSL/TLS协议SSL/TLS协议运行机制的概述SSL延迟有多大？HTTPS研究（2）—分解HTTPS连接建立过程","pubDate":"Fri, 22 Jul 2016 15:09:25 GMT","guid":"http://yikun.github.io/2016/07/22/一次有关OpenStack请求的性能问题分析/","category":"OpenStack"},{"title":"一致性哈希算法的理解与实践","link":"http://yikun.github.io/2016/06/09/一致性哈希算法的理解与实践/","description":"0. 概述在维基百科中，是这么定义的 一致哈希是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n个关键字重新映射，其中K是关键字的数量， n是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。 1. 引出 我们在上文中已经介绍了一致性Hash算法的基本优势，我们看到了该算法主要解决的问题是：当slot数发生变化时，能够尽量少的移动数据。那么，我们思考一下，普通的Hash算法是如何实现？又存在什么问题呢？那么我们引出一个问题： 假设有1000w个数据项，100个存储节点，请设计一种算法合理地将他们存储在这些节点上。 看一看普通Hash算法的原理：算法的核心计算如下 123456for item in range(ITEMS): k = md5(str(item)).digest() h = unpack_from(\"&gt;I\", k)[0] # 通过取余的方式进行映射 n = h % NODES node_stat[n] += 1 具体的完整实现请参考normal_hash.py，输出是这样的： Ave: 100000Max: 100695 (0.69%)Min: 99073 (0.93%) 从上述结果可以发现，普通的Hash算法均匀地将这些数据项打散到了这些节点上，并且分布最少和最多的存储节点数据项数目小于1%。之所以分布均匀，主要是依赖Hash算法（实现使用的MD5算法）能够比较随机的分布。 然而，我们看看存在一个问题，由于该算法使用节点数取余的方法，强依赖node的数目，因此，当是node数发生变化的时候，item所对应的node发生剧烈变化，而发生变化的成本就是我们需要在node数发生变化的时候，数据需要迁移，这对存储产品来说显然是不能忍的，我们观察一下增加node后，数据项移动的情况： 123456789for item in range(ITEMS): k = md5(str(item)).digest() h = unpack_from(\"&gt;I\", k)[0] # 原映射结果 n = h % NODES # 现映射结果 n_new = h % NEW_NODES if n_new != n: change += 1 详细实现代码在normal_hash_add.py输出是这样的： Change: 9900989 (99.01%) 翻译一下就是，如果有100个item，当增加一个node，之前99%的数据都需要重新移动。 这显然是不能忍的，普通哈希算法的问题我们已经发现了，如何对其进行改进呢？没错，我们的一致性哈希算法闪亮登场。 2. 登场我们上节介绍了普通Hash算法的劣势，即当node数发生变化（增加、移除）后，数据项会被重新“打散”，导致大部分数据项不能落到原来的节点上，从而导致大量数据需要迁移。 那么，一个亟待解决的问题就变成了：当node数发生变化时，如何保证尽量少引起迁移呢？即当增加或者删除节点时，对于大多数item，保证原来分配到的某个node，现在仍然应该分配到那个node，将数据迁移量的降到最低。 一致性Hash算法的原理是这样的： 12345678910for n in range(NODES): h = _hash(n) ring.append(h) ring.sort() hash2node[h] = nfor item in range(ITEMS): h = _hash(item) n = bisect_left(ring, h) % NODES node_stat[hash2node[ring[n]]] += 1 我们依然对其进行了实现consist_hash_add.py，并且观察了数据迁移的结果： Change: 235603 (2.36%) 虽然一致性Hash算法解决了节点变化导致的数据迁移问题，但是，我们回过头来再看看数据项分布的均匀性，进行了一致性Hash算法的实现consist_hash.py： Ave: 100000Max: 596413 (496.41%)Min: 103 (99.90%) 这结果简直是简直了，确实非常结果差，分配的很不均匀。我们思考一下，一致性哈希算法分布不均匀的原因是什么？从最初的1000w个数据项经过一般的哈希算法的模拟来看，这些数据项“打散”后，是可以比较均匀分布的。但是引入一致性哈希算法后，为什么就不均匀呢？数据项本身的哈希值并未发生变化，变化的是判断数据项哈希应该落到哪个节点的算法变了。因此，主要是因为这100个节点Hash后，在环上分布不均匀，导致了每个节点实际占据环上的区间大小不一造成的。 3. 改进-虚节点当我们将node进行哈希后，这些值并没有均匀地落在环上，因此，最终会导致，这些节点所管辖的范围并不均匀，最终导致了数据分布的不均匀。 详细实现请见virtual_consist_hash.py 1234567891011121314for n in range(NODES): for v in range(VNODES): h = _hash(str(n) + str(v)) # 构造ring ring.append(h) # 记录hash所对应节点 hash2node[h] = nring.sort()for item in range(ITEMS): h = _hash(str(item)) # 搜索ring上最近的hash n = bisect_left(ring, h) % (NODES*VNODES) node_stat[hash2node[ring[n]]] += 1 输出结果是这样的： Ave: 100000Max: 116902 (16.90%)Min: 9492 (90.51%) 因此，通过增加虚节点的方法，使得每个节点在环上所“管辖”更加均匀。这样就既保证了在节点变化时，尽可能小的影响数据分布的变化，而同时又保证了数据分布的均匀。也就是靠增加“节点数量”加强管辖区间的均匀。同时，观察增加节点后数据变动情况，详细的代码请见virtual_consist_hash_add.py： 123456for item in range(ITEMS): h = _hash(str(item)) n = bisect_left(ring, h) % (NODES*VNODES) n2 = bisect_left(ring2, h) % (NODES2*VNODES) if hash2node[ring[n]] != hash2node2[ring2[n2]]: change += 1 100000101000Change: 104871 (1.05%) 3. 另一种改进 然而，虚节点这种靠数量取胜的策略增加了存储这些虚节点信息所需要的空间。在OpenStack的Swift组件中，使用了一种比较特殊的方法来解决分布不均的问题，改进了这些数据分布的算法，将环上的空间均匀的映射到一个线性空间，这样，就保证分布的均匀性。代码实现见part_consist_hash.py 123456789for part in range(2 ** LOG_NODE): ring.append(part) part2node[part] = part % NODESfor item in range(ITEMS): h = _hash(item) &gt;&gt; PARTITION part = bisect_left(ring, h) n = part % NODES node_stat[n] += 1 Ave: 100000Max: 157298 (57.30%)Min: 77405 (22.59%) 可以看到，数据分布是比较理想的。如果节点数刚好和分区数相等，理论上是可以均匀分布的。而观察下增加节点后的数据移动比例，代码实现见part_consist_hash.py 123456789101112131415for part in range(2 ** LOG_NODE): ring.append(part) part2node[part] = part % NODES part2node2[part] = part % NODES2change = 0for item in range(ITEMS): h = _hash(item) &gt;&gt; PARTITION p = bisect_left(ring, h) p2 = bisect_left(ring, h) n = part2node[p] % NODES n2 = part2node2[p] % NODES2 if n2 != n: change += 1 结果如下所示： Change: 2190208 (21.90%) 可以看到，移动也是比较理想的。 参考链接：深入云存储系统Swift核心组件：Ring实现原理剖析Basic Hash RingPartition Ring vs. Hash Ring","pubDate":"Thu, 09 Jun 2016 02:43:54 GMT","guid":"http://yikun.github.io/2016/06/09/一致性哈希算法的理解与实践/","category":"系统"},{"title":"理解Python中的“with”","link":"http://yikun.github.io/2016/04/15/理解Python中的“with”/","description":"1. 缘起Python中，打开文件的操作是非常常见的，也是非常方便的，那么如何优雅的打开一个文件？大部分的同学会这样实现： 12with open( \"a.txt\" ) as f : # do something 大家都知道，这样写可以自动处理资源的释放、处理异常等，化简了我们打开文件的操作，那么，with到底做了什么呢？ 从《Python学习手册》中是这么描述的： 简而言之，with/as语句的设计是作为常见try/finally用法模式的替代方案。就像try/finally语句，with/as语句也是用于定义必须执行的终止或“清理”行为,无论步骤中是否发生异常。不过，和try/finally不同的是，with语句支持更丰富的基于对象的协议，可以为代码块定义支持进入和离开动作。 也就是说对于代码： 12with expression [as varible]: with-block with语句的实际工作方式： 1.计算表达式，所得到的对象是环境管理器，他必须有enter，exit两个方法。2.环境管理器的enter方法会被调用。如果as存在，enter的返回值赋值给as后面的变量，否则，被丢弃。3.代码块中嵌套的代码（with-block）会执行。4.如果with代码块会引发异常，exit(type,value,traceback)方法就会被调用。这些也是由sys.exec_info返回相同的值。如果此方法返回为假，则异常会重新引发。否则，异常会中止。正常情况下异常是应该被重新引发，这样的话传递到with语句外。5.如果with代码块没有引发异常，exit方法依然会调用，其type、value以及traceback参数会以None传递。 with/as语句的设计，是为了让必须在程序代码块周围发生的启动和终止活动一定会发生。和try/finally语句（无论异常是否发生其离开动作都会执行）类似，但是with/as有更丰富的对象协议，可以定义进入和离开的动作。 2. 设计的初衷with/as语句的设计的初衷，在PEP343中是这么描述的： This PEP adds a new statement “with” to the Python language to make it possible to factor out standard uses of try/finally statements.In this PEP, context managers provide enter() and exit() methods that are invoked on entry to and exit from the body of the with statement. 对于下面的操作： 12with EXPR as VAR: BLOCK 等价于 1234567891011121314151617181920mgr = (EXPR)exit = type(mgr).__exit__ # Not calling it yetvalue = type(mgr).__enter__(mgr)exc = Truetry: try: # 将__enter__函数调用的返回值返回给VAR VAR = value # Only if \"as VAR\" is present # 执行BLOCK BLOCK except: # 异常处理，The exceptional case is handled here exc = False if not exit(mgr, *sys.exc_info()): raise # The exception is swallowed if exit() returns truefinally: # 清理，The normal and non-local-goto cases are handled here if exc: exit(mgr, None, None, None) 我们可以看到上述代码完整的处理了初始化及异常/正常场景的清理操作，这便是with的设计思想，化简了冗余的代码，把那些重复的工作以及异常处理操作交给写“EXPR”源码（比如open操作）的同学。 3. 更深入的学习我们继续深入的看下Python3中enter和exit的实现： 12345678910111213class IOBase(metaclass=abc.ABCMeta): # ... ... ### Context manager ### def __enter__(self): # That's a forward reference \"\"\"Context management protocol. Returns self (an instance of IOBase).\"\"\" self._checkClosed() return self def __exit__(self, *args): \"\"\"Context management protocol. Calls close()\"\"\" self.close() 和我们预期的一致，在enter中返回了这个IO对象，然后在exit中，进行了清理。 参考资料 《Python学习手册》 Understanding Python’s “with” statement PEP 343 — The “with” Statement Catching an exception while using a Python ‘with’ statement 理解Python中的with…as…语法 PEP 3116 — New I/O Python 3.5.0 Code","pubDate":"Fri, 15 Apr 2016 15:44:15 GMT","guid":"http://yikun.github.io/2016/04/15/理解Python中的“with”/","category":"Python"},{"title":"存储数据包的一生","link":"http://yikun.github.io/2016/04/03/存储数据包的一生/","description":"最近认认真真学习了一个叫《Life of a Storage Packet》讲座，借助这个讲座将整个存储的过程理解了下，不放过任何一个有疑问的点。这篇文章算是对讲座的理解和自己收获的总结，同时也为那些对存储系统不够了解又想要了解的初学者，展现一个存储数据包的“生命”。这个演讲主要聚焦在“整体的存储”，强调存储系统中各个基本元素的关系，并且尽可能简单、清楚地用一种不同的方式可视化一些存储的概念。 先上一张大图，可以说这篇文章目的就是解释这个图：","pubDate":"Sun, 03 Apr 2016 14:04:23 GMT","guid":"http://yikun.github.io/2016/04/03/存储数据包的一生/","category":"系统"},{"title":"OpenStack源码分析-Cinder中的调度机制","link":"http://yikun.github.io/2016/03/05/OpenStack源码分析-Cinder中的调度机制/","description":"整理了一下目前cinder中支持的调度的Filter和Weigher：后面结合源码看下实现，留坑~","pubDate":"Fri, 04 Mar 2016 16:45:44 GMT","guid":"http://yikun.github.io/2016/03/05/OpenStack源码分析-Cinder中的调度机制/","category":"Cinder"},{"title":"OpenStack源码分析-Service启动流程","link":"http://yikun.github.io/2016/03/05/OpenStack源码分析-Service启动流程/","description":"","pubDate":"Fri, 04 Mar 2016 16:38:21 GMT","guid":"http://yikun.github.io/2016/03/05/OpenStack源码分析-Service启动流程/","category":"OpenStack,Cinder"},{"title":"OpenStack源码分析-挂载卷流程","link":"http://yikun.github.io/2016/03/05/OpenStack源码分析-挂载卷流程/","description":"1. 挂卷流程 当Nova volume-attach server volume执行后，主要经过以下几步：a. Nova Client解析指令，通过RESTFUL接口访问nova-api；b. Nova API解析响应请求获取虚拟机的基本信息，然后向cinder-api发出请求保留，并向nova-compute发送RPC异步调用请求卷挂载；c. Nova-compute向cinder-api初始化信息，并根据初始化连接调用Libvirt的接口完成挂卷流程；d. 进而调用cinder-volume获取连接，获取了连接后，通过RESTFUL请求cinder-api进行数据库更新操作。","pubDate":"Fri, 04 Mar 2016 16:32:58 GMT","guid":"http://yikun.github.io/2016/03/05/OpenStack源码分析-挂载卷流程/","category":"Cinder"},{"title":"优雅地调试OpenStack","link":"http://yikun.github.io/2016/02/23/优雅地调试OpenStack/","description":"恩，题目首先要起的高逼格一些。2333。 在前面学习代码的过程中，主要通过源码来学习，开始学起来确实有点费劲，因为欠缺对OpenStack的整体的意识，于是搭建OpenStack开发环境对OpenStack的运行环境和使用有了初步认知。也看到了启动OpenStack后的一些相关进程，那么这些进程是如何与源码对应起来的呢？如何去调试OpenStack呢？本篇文章就讲下我的探索。","pubDate":"Mon, 22 Feb 2016 16:00:52 GMT","guid":"http://yikun.github.io/2016/02/23/优雅地调试OpenStack/","category":"OpenStack"},{"title":"OpenStack源码分析-Cinder删除卷流程","link":"http://yikun.github.io/2016/02/21/OpenStack源码分析-Cinder删除卷流程/","description":"1. Cinder删除卷整体流程 删除卷流程比较简单，主要就是cinder-api解析Cilent的指令，并响应，发送RPC调用cinder-volume的delete操作，详细流程如下：a. Client发送删除指令，通过RESTful接口访问cinder-api；b. Cinder-api解析响应请求，通过RPC调用cinder-volume；c. Cinder-volume通过调用Driver的delete函数进行删除。 2. 源码详解 2.1 Cinder API(1) Cinder\\api\\v2\\volumes.pyVolumeController的delete函数响应请求，首先从API获取Volume对象信息，然后，调用API的delete对对象进行删除；(2) Cinder\\volume\\api.pyAPI.delete的对卷的状态进行检查，并更新状态为“deleting”，然后调用rpcapi的delete_volume函数 2.2 Cinder Volume(1) Cinder\\volume\\rpcapi.pyVolumeAPI函数投递一个远程消息，通过消息队列远程调用cinder volume的delete_volume函数。(2) Cinder\\volume\\manager最终通过VolumeManager调用dirver的delete_volume对卷进行删除。","pubDate":"Sun, 21 Feb 2016 11:56:59 GMT","guid":"http://yikun.github.io/2016/02/21/OpenStack源码分析-Cinder删除卷流程/","category":"OpenStack,Cinder"},{"title":"OpenStack源码分析-Cinder创建卷流程","link":"http://yikun.github.io/2016/02/14/OpenStack源码分析-Cinder创建卷流程/","description":"1. Cinder创卷整体流程 如整体架构图所示，创建卷涉及的答题步骤主要有以下几步：a. Client发送请求，通过RESTFUL接口访问cinder-api。b. Api解析响应请求，api解析由Client发送来的请求，并通过rpc进一步调用cinder-scheduler。c. Scheduler对资源进行调度，scheduler选择合适的节点进行。d. Volume调用Driver创建卷，volume通过指定Driver进行卷的创建。 2. 源码详解代码的整体流程如下所示： 从上图可以看出，整体处理流程包括三大部分，分别是API、Scheduler、Volume三部分。 2.1 Cinder API部分 (1) cinder\\api\\v2\\volumes.pyVolumeController. create函数对创建请求进行响应，首先函数对volume_type、metadata、snapshot等信息进行检查，然后调用Volume API的create进行创建。(2) cinder\\volume\\api.pyAPI.create函数对source_volume、volume_type等参数进行进一步检查，并调用cinder.volume.flows.api.get_flow来创建。(3) cinder\\volume\\flows\\api\\create_volume.pyget_flow函数检查Quata，最后创建EntryCreateTask及VolumeCastTask等任务，其中EntryCreateTask会将卷的创建过程写入数据库，此时卷的状态为”creating”。VolumeCastTask.excute函数会调用VoumeCastTask._cast_create_volumeVolumeCastTask._cast_create_volume函数，如果未传入host，则会经过调度进行创建卷，通过scheduler_rpcapi.create_volume创建卷；如果未传入host则直接交由Volume Manager去创建卷。 至此为止，Cinder API部分完成了自己的工作。 2.2 Cinder Scheduler (1) cinder\\scheduler\\rpcapi.py（此步还属于cinder-api）SchedulerAPI.create_volume函数会通过消息异步调用SchedulerManager.create_volume函数。(2) cinder\\scheduler\\manager.pySchedulerManager.create_volume函数，使用自己的flow来创建volume，其中还传入了Driver。(3) cinder\\scheduler\\flows\\create_volume.pyget_flow函数，创建ScheduleCreateVolumeTaskScheduleCreateVolumeTask.execute函数，会调用driver_api.schedule_create_volume(4) cinder\\scheduler\\filter_scheduler.pyFilterScheduler. schedule_create_volume函数，更新数据库，最后通过消息队列请求调用volume_rpcapi.create_volume。 2.3 Cinder Volume (1) /cinder/volume/rpcapi.py（此步还属于cinder-scheduler）VolumeAPI.create_volume会通过消息队列远程调用VolumeManager.create_volume(2) /cinder/volume/manager.pyVolumeManager函数也使用flow来创建volume，执行CreateVolumeFromSpecTask这个任务(3) /cinder/volume/flows/manager/create_volume.pyCreateVolumeFromSpecTask.excute，这个函数会根据创建的不同类别，去创建卷，例如调用create_raw_volume，最终会调用具体的driver进行卷的创建。在完成创卷后，CreateVolumeOnFinishTask这个任务，启动更新数据库，将卷更新为available状态。 我们可以看到在创建卷的过程中盘的状态会从“creating”状态变为“available”状态。","pubDate":"Sun, 14 Feb 2016 09:43:30 GMT","guid":"http://yikun.github.io/2016/02/14/OpenStack源码分析-Cinder创建卷流程/","category":"OpenStack,Cinder"},{"title":"搭建OpenStack开发环境","link":"http://yikun.github.io/2016/02/10/搭建OpenStack开发环境/","description":"前段时间主要了解了一些OpenStack相关的基础性东西，现在希望通过安装使用来增强一下对系统整体的认识，最近也读了一篇文章如何学习开源项目，基本和我的想法很类似，所以基本上也就是按照这个节奏来的。不说废话了，开始。","pubDate":"Tue, 09 Feb 2016 16:10:09 GMT","guid":"http://yikun.github.io/2016/02/10/搭建OpenStack开发环境/","category":"OpenStack"},{"title":"存储知识学习","link":"http://yikun.github.io/2016/02/03/存储知识学习/","description":"1. 磁盘基本知识磁盘大致由盘片、磁头、步进电机等几部分组成组成。盘面：硬盘一般含有一个或多个盘片，一个盘片包含两个盘面。磁道：每个盘面被划成多个狭窄的同心圆环，这样的圆环叫做磁道。扇区：每个磁道的每段圆弧叫做一个扇区，是读写的最小单位。柱面：所有盘面上的同一磁道，在竖直方向构成一个圆柱，称为柱面。 读写过程：硬盘读取数据时，磁头先移动到读取扇区所在磁道的上方，这个过程耗时叫做磁盘寻道时间，平均时间为10ms。之后，通过盘片的旋转，使得扇区转到磁头的下方，这个过程耗时叫做旋转延迟时间，对于7200转/min的硬盘转一周为60*1000/7200=8.33ms，平均旋转延迟为4.17ms（半圈）。 2. RAID基本知识RAID（Redundant Array of Independent Disks），即由独立的磁盘组成的具有冗余特性的阵列。其基本思想就是把多个相对便宜的硬盘组合起来，成为一个硬盘阵列组，使性能达到甚至超过一个价格昂贵、 容量巨大的硬盘。RAID 0，条带化存储，容量增加，并行化，但无冗余，容易单点故障。 RAID 1，镜像存储，写入速率慢，读取速率快，有冗余备份，优点是高可靠、高可用，缺点是高花费。 RAID 2，RAID 0的改进版，使用汉明码进行检测和纠错，适用于连续IO、大块IO（如视频流）。 RAID 3，RAID 3和RAID 2的思路比较相似，使用奇偶校验进行错误检测和纠错，但校验盘单点故障。 RAID 4，RAID 4和RAID 3思路一样，只不过是使用BLOCK进行存储。 RAID 5，校验信息交叉的存储在所有数据盘上，高冗余，高数据传输率，实现复杂。 RAID 6，相比RAID5增加块内的校验，允许同时坏2块硬盘而不丢失数据。 RAID 01，先做条带（0），再做镜像（1）。读写速度快，数据保护能力强，空间利用率50%。RAID 10，先做镜像（1），再做条带（0）。 3. 存储方式根据网上的资料和理解，用Visio整理了一张图对比了下几种方式： DAS全称为Direct Attached Storage，即服务器直连存储。如图所示，文件系统直接通过RAID完成对硬件访问。优点是操作简便，经济，缺点是分散式存储，不可集中管理。NAS全称为Network Attached Storage，即网络存储服务。如图所示，文件系统通过网络暴露出来给应用服务。优点是结构简单。配置使用管理非常方便，可实现跨平台的数据共享。缺点是需要占用网络资源、应用局限性大。SAN全称为Storage Aera Network，即存储区域网络，如图所示，RAID接口通过网络暴露出来。优点是扩展性强，集中管理，缺点是成本较高，管理维护难度大。 4. IP SAN与FC SANFC SAN指基于光纤通道（Fiber Channel）的存储区域网，在FC SAN中存在两张网，一张面向应用的网（IP网），另一张中则是存储网（FC网）。而IP SAN的出现则是为了寻求一种新的方式，用与应用网相同的体系架构来构造存储网，使用通用的IP网络及设备。FC SAN性能好，价格高，但与主流的IP网络异构。适用于关键应用的几种存储、备份及容灾。IP SAN则由于以太网MTU（1518字节）的限制，性能稍差，但基于通用的IP协议。适用于异地间的数据交换、备份容灾，非关键应用的集中存储。 5. LVM基本知识LVM的全称是Logical Volume Manager，逻辑卷轴管理，主要解决的问题是，弹性调整文件系统的容量。 与传统的磁盘与分区相比，LVM为计算机提供了更高层次的存储，通过在磁盘分区和文件系统之间增加一个逻辑层，提供一个抽象的逻辑盘卷。 参考资料 《大话存储》 RAID技术介绍和总结http://blog.jobbole.com/83808/ 基于OpenStack的NAS服务https://www.ustack.com/blog/openstack-nas/","pubDate":"Wed, 03 Feb 2016 14:46:58 GMT","guid":"http://yikun.github.io/2016/02/03/存储知识学习/","category":"OpenStack,Cinder"},{"title":"[译]Internationalization","link":"http://yikun.github.io/2016/01/23/译-Internationalization/","description":"Nova uses the oslo.i18n library to support internationalization. The oslo.i18n library is built on top of gettext and provides functions that are used to enable user-facing strings such as log messages to appear in the appropriate language in different locales. Nova exposes the oslo.i18n library support via the nova/i18n.py integration module. This module provides the functions needed to wrap translatable strings. It provides the _() wrapper for general user-facing messages and specific wrappers for messages used only for logging. DEBUG level messages do not need translation but CRITICAL, ERROR, WARNING and INFO messages should be wrapped with _LC(), _LE(), _LW() or _LI() respectively. 理解：Nova是通过oslo.i18n来支持国际化的，oslo.i18n是基于getnext做的，这个库可以把面向用户的字符（比如日志）翻译成指定的语言。其中DEBUG信息不翻译，其他的信息会被翻译。 比如： 1234567# debug logLOG.debug(\"block_device_mapping %(mapping)s\", &#123;'mapping': block_device_mapping&#125;)# warn logLOG.warn(_LW('Unknown base file %(img)s'), &#123;'img': img&#125;)# not lograise nova.SomeException(_('Invalid service catalogue')) Do not use locals() for formatting messages because: 1. It is not as clear as using explicit dicts. 2. It could produce hidden errors during refactoring. 3. Changing the name of a variable causes a change in the message. 4. It creates a lot of otherwise unused variables. If you do not follow the project conventions, your code may cause hacking checks to fail. 另外，文中提到了不要使用locals()去格式化消息主要4点原因：1.不清楚是否有关键字. 2.重构时会有潜在的出错可能. 3.变量名变了消息就变. 4.创建很多无用的变量。 这些函数_(), _LC(), _LE(), _LW() and _LI()可以通过以下方法导入： 12345from nova.i18n import _from nova.i18n import _LCfrom nova.i18n import _LEfrom nova.i18n import _LWfrom nova.i18n import _LI","pubDate":"Fri, 22 Jan 2016 16:43:37 GMT","guid":"http://yikun.github.io/2016/01/23/译-Internationalization/","category":"Nova"},{"title":"[译]Virtual Machine States and Transitions","link":"http://yikun.github.io/2016/01/20/译-Virtual-Machine-States-and-Transitions/","description":"虚拟机的状态及其转移，主要讲了一些虚拟机的状态以及在创建虚拟机时的状态转移情况，目前理解不够深刻，需要在后面看代码时，进一步深入理解。","pubDate":"Wed, 20 Jan 2016 15:46:59 GMT","guid":"http://yikun.github.io/2016/01/20/译-Virtual-Machine-States-and-Transitions/","category":"Nova"},{"title":"2015，再见","link":"http://yikun.github.io/2016/01/02/2015，再见/","description":"2015年是很特殊的一年，是长达快20年的学生时代的终结。从年初最开始的时候，就对今年的会发生的事情做好了准备，也基本上按照自己的想法发生了。之前，也有一些计划，基本达到预期，现在想起这些目标都算是一些学生时代的梦想吧，这篇总结也大致的从这些方面展开。","pubDate":"Fri, 01 Jan 2016 16:05:42 GMT","guid":"http://yikun.github.io/2016/01/02/2015，再见/","category":"随笔"},{"title":"Python3源码学习-整型","link":"http://yikun.github.io/2015/12/21/Python3源码学习-整型/","description":"1. 引入我们先看看对整型变量i进行赋值，并对i进行显示的过程： 123&gt;&gt;&gt; i=1&gt;&gt;&gt; i1","pubDate":"Mon, 21 Dec 2015 13:48:29 GMT","guid":"http://yikun.github.io/2015/12/21/Python3源码学习-整型/","category":"Python"},{"title":"Python3源码学习-类型","link":"http://yikun.github.io/2015/12/20/Python3源码学习-类型/","description":"1. 类型我们在《Python3源码学习-对象》中提到了每个对象都含有一个type的属性，我们看看type是个什么东西，目光移到object.h： 1234567891011121314151617181920typedef struct _typeobject &#123; PyObject_VAR_HEAD const char *tp_name; /* For printing, in format \"&lt;module&gt;.&lt;name&gt;\" */ Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */ /* Methods to implement standard operations */ destructor tp_dealloc; //... ... /* More standard operations (here for binary compatibility) */ hashfunc tp_hash; ternaryfunc tp_call; reprfunc tp_str; getattrofunc tp_getattro; setattrofunc tp_setattro; //... ...&#125; PyTypeObject;","pubDate":"Sun, 20 Dec 2015 15:03:21 GMT","guid":"http://yikun.github.io/2015/12/20/Python3源码学习-类型/","category":"Python"},{"title":"Python3源码学习-编译Python源码","link":"http://yikun.github.io/2015/12/20/Python3源码学习-编译Python源码/","description":"在进行源码学习的时候，“实践出真知”。因此，在进行源码学习的过程中，我们首先需要对源码进行编译，然后，对我们感兴趣的点进行log，甚至debug。本篇文章记录了我在进行Python 3.5.0源码编译时的一些过程。","pubDate":"Sun, 20 Dec 2015 12:36:58 GMT","guid":"http://yikun.github.io/2015/12/20/Python3源码学习-编译Python源码/","category":"Python"},{"title":"Python3源码学习-对象","link":"http://yikun.github.io/2015/12/03/Python3源码学习-对象/","description":"最近开始看Python源码，大致看了看，发现Py2和Py3的部分实现差别挺大，《Python源码剖析》是根据Python 2写的。不过为了能激发主动性，便直接从Python 3（3.5.0）源码看起了，然后也会结合Python 2（2.7.10）的代码看看之前的实现，来对比学习~：） 1. 万物皆对象在Python中，万物皆对象，那么对象又是什么结构，如何组织，怎样实现的呢？","pubDate":"Thu, 03 Dec 2015 07:07:19 GMT","guid":"http://yikun.github.io/2015/12/03/Python3源码学习-对象/","category":"Python"},{"title":"网络知识拾遗","link":"http://yikun.github.io/2015/11/23/网络知识拾遗/","description":"本科加上研究生大概有七年时间，一直都是学的通信，不过覆盖面不是很全，一直对一些网络相关的概念和实现有些模糊。最近补了补通信网络中的一些基础知识和盲点，有目的地看了看《云计算网络珠玑》、《图解网络硬件》等和网络相关的书和一些文章，做一下记录总结。主要包括了二层交换、三层路由、Linux网络相关的内容。","pubDate":"Mon, 23 Nov 2015 13:19:23 GMT","guid":"http://yikun.github.io/2015/11/23/网络知识拾遗/","category":"网络"},{"title":"[译]Threading model","link":"http://yikun.github.io/2015/11/19/译-Threading-model/","description":"Threading model All OpenStack services use green thread model of threading, implemented through using the Python eventlet and greenlet libraries. Green threads use a cooperative model of threading: thread context switches can only occur when specific eventlet or greenlet library calls are made (e.g., sleep, certain I/O calls). From the operating system’s point of view, each OpenStack service runs in a single thread. The use of green threads reduces the likelihood of race conditions, but does not completely eliminate them. In some cases, you may need to use the @lockutils.synchronized(…) decorator to avoid races. In addition, since there is only one operating system thread, a call that blocks that main thread will block the entire process. 理解：OpenStack的所有服务都使用Green thread，使用eventlet和greenlet库，绿色线程使用协作并发模型，线程的切换只在eventlet或greenlet库调用一些切换时发生。从操作系统角度上来看，每个OpenStack运行在一个单一线程。用Green Thread的好处是能够减少race conditions，当然有些时候我们也必须使用@lockutils.synchronized(…)来完全避免。因为只用一个系统级别的单线程，所以调用一旦阻塞就会阻塞整个进程。 关于Python中的并发模型，可以参考Python并发模型一文，把Thread（线程切换耗资源）、MicroThread（依靠解释器调度）、Green thread（协作并发）的特点对比了下。 还有Python几种并发实现方案的性能比较将Python中的集中并发方案进行了对比和说明。 Yielding the thread in long-running tasks If a code path takes a long time to execute and does not contain any methods that trigger an eventlet context switch, the long-running thread will block any pending threads. This scenario can be avoided by adding calls to the eventlet sleep method in the long-running code path. The sleep call will trigger a context switch if there are pending threads, and using an argument of 0 will avoid introducing delays in the case that there is only a single green thread: 123from eventlet import greenthread...greenthread.sleep(0) 理解：对于那些耗时很长的任务，需要我们添加一些yield方法，来避免在单个的调用中阻塞很久。 MySQL access and eventlet Queries to the MySQL database will block the main thread of a service. This is because OpenStack services use an external C library for accessing the MySQL database. Since eventlet cannot use monkey-patching to intercept blocking calls in a C library, the resulting database query blocks the thread. The Diablo release contained a thread-pooling implementation that did not block, but this implementation resulted in a bug and was removed. 理解：对于MySQL数据的查询会阻塞服务，因为eventlet对C库的调用是无法去做monkey-patching的。","pubDate":"Thu, 19 Nov 2015 13:34:04 GMT","guid":"http://yikun.github.io/2015/11/19/译-Threading-model/","category":"OpenStack"},{"title":"[译]Host Aggregates","link":"http://yikun.github.io/2015/10/17/译-Host-Aggregates/","description":"先上一个自己画的图，非常有助于理解Host Aggregates:","pubDate":"Sat, 17 Oct 2015 03:15:40 GMT","guid":"http://yikun.github.io/2015/10/17/译-Host-Aggregates/","category":"OpenStack,Nova"},{"title":"[译]Scope of the Nova project","link":"http://yikun.github.io/2015/10/16/译-Scope-of-the-Nova-project/","description":"Scope of the Nova project Nova is focusing on doing an awesome job of its core mission. This document aims to clarify that core mission. This is a living document to help record where we agree about what Nova should and should not be doing, and why. Please treat this as a discussion of interesting, and hopefully useful, examples. It is not intended to be an exhaustive policy statement. 理解：文档的主要内容是，理清Nova的核心使命。","pubDate":"Fri, 16 Oct 2015 12:02:54 GMT","guid":"http://yikun.github.io/2015/10/16/译-Scope-of-the-Nova-project/","category":"OpenStack,Nova"},{"title":"[译]Nova System Architecture","link":"http://yikun.github.io/2015/10/15/译-Nova-System-Architecture/","description":"Nova系统架构 Nova is built on a shared-nothing, messaging-based architecture. All of the major nova components can be run on multiple servers. This means that most component to component communication must go via message queue. In order to avoid blocking each component while waiting for a response, we use deferred objects, with a callback that gets triggered when a response is received. Nova建立在一个无共享，基于消息的架构。所有的nova主要组件都可以运行在不同的服务器。这就意味着大多数组件之间的通信必须通过消息队列。为了避免每个组件在等待响应时的阻塞，我们是用deferred对象，当一个响应接收时会触发相应的回调。","pubDate":"Thu, 15 Oct 2015 02:04:44 GMT","guid":"http://yikun.github.io/2015/10/15/译-Nova-System-Architecture/","category":"OpenStack,Nova"}]}