{"title":"Yikun","description":null,"language":null,"link":"http://yikun.github.io","pubDate":"Mon, 25 Dec 2017 09:25:17 GMT","lastBuildDate":"Fri, 19 Jan 2018 14:18:56 GMT","generator":"hexo-generator-json-feed","webMaster":"Yikun","items":[{"title":"[Placement深度探索] Get Allocation Candidates","link":"http://yikun.github.io/2017/12/25/Placement深度探索-Get-Allocation-Candidates/","description":"1 功能概述Placement的一个重要的接口，就是获取满足指定资源条件的allocation。举个例子，用户说，我需要1个VCPU，512MB内存，1GB磁盘的资源，Placement你帮我找找看看，有没有合适的资源。","pubDate":"Mon, 25 Dec 2017 09:25:17 GMT","guid":"http://yikun.github.io/2017/12/25/Placement深度探索-Get-Allocation-Candidates/","category":"Nova,OpenStack,Draft"},{"title":"一个死锁问题的深入探究","link":"http://yikun.github.io/2017/12/13/一个死锁问题的深入探究/","description":"本篇文章可以看做是一个问题定位、分析、学习过程的记录，介绍了OpenStack Nova一个死锁问题的分析和解决的过程，你将从本文了解到SQLAlchemy的session中的语序排序机制、OpenStack的死锁重试机制及改进点以及一些调试的手段。 0. 背景在Nova对虚拟机进行一些操作的时候，比如创建、停止虚拟机之类的操作的时候，会将这些事件记录在instance_actions表里面记录操作的时间、操作类型以及一些操作事件详情。 例如，我们可以通过instnace-action-list来查看虚拟机的操作，并可以通过对应的req id来查操作中的事件详情，如果是失败的话，还可以从事件详情中，看到对应的错误栈信息。12345678910111213141516171819202122232425$ nova instance-action-list e92885a9-06d6-4491-ac43-6fd04e32ee72+--------+------------------------------------------+---------+----------------------------+| Action | Request_ID | Message | Start_Time |+--------+------------------------------------------+---------+----------------------------+| create | req-416cb88e-5adb-4c0f-9c32-6370d3661940 | - | 2017-12-13T12:08:36.000000 || stop | req-52155da3-d2ca-463c-b380-6034c0b5fdf1 | - | 2017-12-13T12:09:17.000000 |+--------+------------------------------------------+---------+----------------------------+$ nova instance-action e92885a9-06d6-4491-ac43-6fd04e32ee72 req-52155da3-d2ca-463c-b380-6034c0b5fdf1+---------------+--------------------------------------------------+| Property | Value |+---------------+--------------------------------------------------+| action | stop || events | [&#123;u'event': u'compute_stop_instance', || | u'finish_time': u'2017-12-13T12:09:23.000000', || | u'result': u'Success', || | u'start_time': u'2017-12-13T12:09:18.000000', || | u'traceback': None&#125;] || instance_uuid | e92885a9-06d6-4491-ac43-6fd04e32ee72 || message | - || project_id | 0232cef222f7479fae3fd8fa24d8c382 || request_id | req-52155da3-d2ca-463c-b380-6034c0b5fdf1 || start_time | 2017-12-13T12:09:17.000000 || user_id | 5b0b6a4c068f4c1ba78b50d8a4db5057 |+---------------+--------------------------------------------------+ 在instance_action的表里面，记录着action的更新时间，比如event结束了，我们也期望能够action里面能记录update的时间，但是目前并没有进行刷新。 这个patch想做的事儿也比较简单，如上图所示，就是在event进行记录（比如开始和结束）的时候，也对action的更新时间也做刷新。也就是说，我们在写instance_event_action表后，也需要写instance_action表去记录下刷新时间。大致代码的关键逻辑如下所示（省略了一些无关的代码细节）：1234567891011121314151617@pick_context_manager_writerdef action_event_finish(context, values): \"\"\"Finish an event on an instance action.\"\"\" # 原有获取action action = _action_get_by_request_id(context, values['instance_uuid'], values['request_id']) # 原有获取event event_ref = model_query(context, models.InstanceActionEvent).\\ filter_by(action_id=action['id']).\\ filter_by(event=values['event']).\\ first() # 原有的event刷新流程 event_ref.update(values) # **新增的刷新action时间逻辑** action.update(&#123;'updated_at': values['finish_time']&#125;) action.save(context.session) return event_ref 1. 起因在修复Nova的这个事件时间刷新问题(bug/507473)的时候，CI会概率性地挂一些用例，先开始以为是CI不稳定，workflow+1之后，最终的门禁检查一直过不了。Matt recheck了几次都是失败的，然后问： I’m not sure if the test failures this patch is hitting are related to this change or not - they definitely don’t seem to be (I’m not sure why we’d get an UnexpectedTaskStateError during resize due to this change). 这才引起了我的注意，我找了下归档的日志发现： Exception during message handling: DBDeadlock: (pymysql.err.InternalError) (1213, u’Deadlock found when trying to get lock; try restarting transaction’) [SQL: u’UPDATE instance_actions SET updated_at=%(updated_at)s WHERE instance_actions.id = %(instance_actions_id)s‘] [parameters: {‘instance_actions_id’: 23, ‘updated_at’: datetime.datetime(2017, 12, 4, 2, 48, 36, 91068)}] 第一反应是，我去！死锁了？简单的一个update怎么会死锁？确认了下where条件比较单一，并不是因为条件排序不稳定引起的死锁；也确认了下action数据库的索引，也比较简单，也不会有死锁问题。然后，就看业务代码，代码逻辑也很简单，一个事务里面包含了4件事，2个查询，2个刷新。不科学啊！ 2. 发现遇到这种活久见的问题，最好的办法就是把每一句SQL都dump出来，因为不是裸写SQL，鬼知道SQLAlchemy中间的ORM那层为我们做了什么。 OpenStack的oslo.db为我们提供了一个配置项：123[database]# (Integer) Verbosity of SQL debugging information: 0=None, 100=Everything.connection_debug = 100 把他设置成100就可以dump出执行的每一句SQL了，这个方法在我们进行调试的时候很方便。然后，进行复现，结果让我震惊了（问号脸？？？代码是一样的，生成SQL的顺序却是不一致的）：12345678910111213141516171819-- 从API dump的结果BEGIN (implicit)SELECT ... FROM instance_actions WHERE ...SELECT ... FROM instance_actions_events WHERE ...-- 先刷新actionUPDATE instance_actions SET updated_at=%(updated_at)s WHERE instance_actions.id= %(instance_actions_id)s-- 再刷新action_eventUPDATE instance_actions_events SET updated_at=%(updated_at)s, finish_time=%(finish_time)s, result=%(result)s WHERE instance_actions_events.id = %(instance_actions_events_id)sCOMMIT-- 从Conductor dump的结果BEGIN (implicit)SELECT ... FROM instance_actions WHERE ...SELECT ... FROM instance_actions_events WHERE ...-- 先刷新action_eventUPDATE instance_actions_events SET updated_at=%(updated_at)s, finish_time=%(finish_time)s, result=%(result)s WHERE instance_actions_events.id = %(instance_actions_events_id)s-- 再刷新actionUPDATE instance_actions SET updated_at=%(updated_at)s WHERE instance_actions.id= %(instance_actions_id)sCOMMIT 完整的SQL dump我贴在了paste/628609，可以分析出来，就是产生死锁的根本原因：在一个事务中，更新2个表的相反行。并发执行2个这样的事务，一个事务拿着action表的行锁，一个事务拿着action_event表的行锁，它们都互相等着对方释放，最终产生了死锁，如下图所示。 从MySQL官方DOC里，给的建议How to Minimize and Handle Deadlocks中，我们也看到了类似的建议： When modifying multiple tables within a transaction, or different sets of rows in the same table, do those operations in a consistent order each time. Then transactions form well-defined queues and do not deadlock. For example, organize database operations into functions within your application, or call stored routines, rather than coding multiple similar sequences of INSERT, UPDATE, and DELETE statements in different places. 核心意思就是说，我们在一个transaction中更新多个表的时候，或者说在一个表中更新不同行的时候，一定要保证每一次调用的顺序是一致的。最终，临时解决这个问题的方式也比较简单，就是在这个函数上加一个死锁重试装饰器，即在发生死锁的时候进行重试，CI终于全绿了。 3. 进一步分析问题解决就结束了吗？不，2个疑问一直在心中徘徊： 死锁重试的装饰器是怎么实现的，真的有效吗？ SQLalchemy做了什么导致最终生成SQL的顺序是不稳定的，为什么要这么做？ 3.1 死锁重试机制我们从oslo_db/api.py可以看到他的实现，原理比较简单，就是隔几秒（2的retry数次方秒），如果调用成功，就终止重试。伪代码大概如下：12345678910t = 1for i in range(try): sleep(t) # 指数递增 t = t * 2 # 超过上限取上限 t = min(max_t, t) func() if not raise deadlock: break 虽然看着隔了一些时间，但是，这种指数递增的机制对于死锁这种问题没有什么卵用，大家一起等，然后再一起调，还是会再次产生死锁。 这个问题的场景和上研的时候，在通信中搞的“退避算法”很类似（HINOC中信道接纳的时候，多个节点并行接纳时，如果发生冲突，需要退避重试），都是冲突避免，通信中是避免信道冲突，而这里则是避免数据库的死锁。 在退避时间选择的过程中，其实有2个参数，需要我们仔细思考一下： 等待的基数时间。目前时间的基数是，随着重试次数指数增长的，这个基数对于连接失败类的业务是比较有用的，想象一下，这种类型的业务我们重试的目的说白了就是：“过一段时间，试一试，看看能不能正常连上”，那这个时间不断的指数增长是挺有意义的。也就是说，随着重试次数的增加，我们每次等待的时间也会逐渐递增，1秒，2秒，4秒，8秒，16秒等等。 抖动时间窗口。目前的实现，对于时间窗口来说，其实是0，即使我们等待了很久，但是他们还是同时去调用的，没有这个抖动，而单单的增加等待时间基数，只会激增等待时间，而对实际的冲突避免没有什么意思。 我们思考下，对于死锁这种场景来说，我们真的需要具备这两个参数吗？我觉得其实并不需要很长的“等待的基数时间”，我们需要的只是让各种死锁的请求，互相避开即可，所以其实，只需要拉长等待的时间窗口即可。 3.1.1. Non-Jitter，无随机无随机的方式，就是oslo.db目前使用的方式，仅指数增长。 3.1.2. Full Jitter，全量随机所以，我觉得这块可以优化下，在退避sleep的时候，加入随机机制，使得sleep的时间随机化，指数拉长调用的窗口，从而降低再次死锁概率。顺着这个思路，也提了一个patch/527362: Improve exponential backoff for wrap_db_retry，希望能够改进一下重试机制。加上这个机制后，等待时间变为0-1秒，0-2秒，0-4秒，0-8秒，0-16秒等范围内随机。 3.1.3. Top X Jitter，顶部随机提交之后，Micheal Bayer（后面发现这位大神是SQLAlchemy的作者，社区真是卧虎藏龙，哈哈，神奇无处不在）马上给了review，他认为，等待的基数时间，并且在基数时间的上沿边界向下抖动（比如25%）比较好。的确，这种方法来说既保留了“安全”的重试时间，而且抖动时间窗口也在递增。 3.1.4. Other Jitter，其他随机方式另外，我在一个AWS的博客中发现了一篇文章：Exponential Backoff And Jitter，写的非常不错，大致就讲的是，各种随机时间窗口加到退避算法中的流程后，对平均时间和竞争的调用数也做了一个仿真。 很显然，其中，Fulljitter（0~2**n随机，和我的思路比较类似），Equal Jitter（top 50%的边界抖动，和Micheal Bayer的思路比较类似），很显然但抖动范围大，平均抖动时间比较低，但从平均时间和冲突避免这两个指标看，Fulljitter是获胜的。但这并不意味着在所有情况下，我们都需要很低的时间间隔，更长的时间会拥有更“安全”的重试时间，代价则是更耗时了，我想这确实是一个值得思考的tradeoff。 3.2 SQLAlchemy Session中的排序机制上文已经提到，造成死锁的根本原因实际上是在一个事务中，更新2个表的时候的顺序不一致。在并发调用的时候，产生了死锁。Python的代码是按顺序更新的（先更新event内容，再更新action），但是为什么SQLAlchemy产生的SQL是乱序的呢？ 通过阅读SQLAlchemy的源码，最终找到了答案。先说结论：Session中的操作顺序，由UnitOfWork机制决定最终的调用顺序，如果没有依赖关系，最终执行顺序是不稳定的。 3.2.1. SQLAlchemy的缓存刷新机制SQLAlchemy在进行数据刷新的时候，会有一个flush的过程(实现见lib/sqlalchemy/orm/session.py#def flush，这个过程会将所有的object的变化，刷新到数据库中。例如，会将插入、修改、删除，转换为INSERT、UPDATE、DELETE等操作。而刷新执行的顺序，是通过Session的”UNIT of Worker”依赖机制保证的。 我们可以从有SQLalchemy作者写的一篇关于其架构的文章《SQLAlchemy》中看到一些关于Session相关的数据结构： Session维护着如上图所示的结构，在每次刷新的时候，会将object的变动刷新到数据库中。如作者所说说，flush这个函数可能是 SQLAlchemy最复杂的函数。 3.2.2. SQLAlchemy的UNIT of WORK机制我们先看看来自作者的介绍： The job of the unit of work is to move all of the pending state present in a particular Session out to the database, emptying out the new, dirty, and deleted collections maintained by the Session. Once completed, the in-memory state of the Session and what’s present in the current transaction match. The primary challenge is to determine the correct series of persistence steps, and then to perform them in the correct order. UOW的工作主要是将session维护的new、dirty、deleted的集合清掉并落入数据库中。主要挑战就是决定正确的持久化步骤和顺序。我们看到了关键的地方，排序！ 从这篇文章中，我们了解到，其实对于UOW来说，共有两级排序：1） 第一级排序，是针对于多个表（class）之前的排序，依赖信息从表之间的关系获取，例如文章中所举的User和Address的例子，需要在user插入后，有了主键，然后再去更新。2）第二季排序，是针对于一个表（class）之中操作的排序，例如文章中所举的，前一个插入的user依赖后一个user。 然而，无论是哪个排序，如果表和表之间在SQLAlchemy定义模型的时候，并没有指定其顺序，那么便没有依赖关系，也便意味着，顺序是不稳定的。 在我们出现的问题中，action和action_event在model定义的代码中，并未指定action和event之前的关系，因此，SQLAlchemy分析依赖的时候，只是将这两个表当做独立的2个表。 3.2.3. 实战一把为了证明我们的分析，我们在SQLAlchemy打印一些日志来记录依赖关系和最终执行的结果，代码见lib/sqlalchemy/ormunitofwork.py，取消掉这些注释即可。 dependencies: set([(SaveUpdateAll(Mapper|InstanceActionEvent|instance_actions_events), DeleteAll(Mapper|InstanceActionEvent|instance_actions_events)), (SaveUpdateAll(Mapper|InstanceAction|instance_actions), DeleteAll(Mapper|InstanceAction|instance_actions))]) cycles: set([]) sort: [SaveUpdateAll(Mapper|InstanceAction|instance_actions), SaveUpdateAll(Mapper|InstanceActionEvent|instance_actions_events), DeleteAll(Mapper|InstanceActionEvent|instance_actions_events), DeleteAll(Mapper|InstanceAction|instance_actions)] COUNT OF POSTSORT ACTIONS 4 上面共4行信息，我们需要的是dependencies信息和sort信息，从依赖信息我们可以看到，我们进行的这个事务仅有2组依赖，分别是action和event_action的缓存入库先于缓存清空，而action和event_action之间是没有依赖关系的。所以，最终生成的sort列表，其实是无法保证稳定性的。 所以，才会出现我们本文所出的问题，一会先刷新action，一会先刷新action_event。然而，对于这种问题并不是无解，我们只需要在这两个表里加入relationship，使他们有依赖就可以了。如果确实没有什么关联，那我们就需要思考把更新拆分到更小的事务中了，就像MySQL官网说的那样：Keep transactions small and short in duration to make them less prone to collision。 4. 总结。TL;DR。写完这篇文章发现，有点太长了，不想细看的看看总结吧，哈哈。 遇到OpenStack数据库相关问题，可以通过设置[database]/connection_debug=100进行SQL打印。 SQLAlchemy对于一个session中的更新顺序，如果表之间没有依赖，是无法保证顺序的。 在一个事务中，更新多张表，需要考虑顺序，若ORM无法保证的更新顺序，尽量不要放在同一个事务中，尽量确保事务做的事简单。 oslo.db目前的死锁重试机制，是大家一起等X秒，很有可能再次死锁。 参考 Instance action’s updated_at issue How to Minimize and Handle Deadlocks Exponential Backoff And Jitter SQLAlchemy library(tutorials, arch doc, talks, posts Some discussion on backoff algorithm Is SQLAlchemy saves order in adding objects to session? SQLAlchemy at Architecture of Open Source Applications","pubDate":"Wed, 13 Dec 2017 11:47:10 GMT","guid":"http://yikun.github.io/2017/12/13/一个死锁问题的深入探究/","category":"Nova,OpenStack,Python"},{"title":"Nova调度相关特性理解与梳理","link":"http://yikun.github.io/2017/12/06/Nova调度相关特性理解与梳理/","description":"准备拿这篇文章梳理下OpenStack Nova调度相关的特性，由于目前Placement的引入，说起调度，和这个组件是分不开的，所以本文也可以看做是Placement的一个历史特性的梳理。第一阶段会按照版本，先把调度相关的BP过一遍，然后再通过理解和使用加强理解。好吧，我承认又开了一个系列的坑，话不多说，开始！","pubDate":"Wed, 06 Dec 2017 01:41:11 GMT","guid":"http://yikun.github.io/2017/12/06/Nova调度相关特性理解与梳理/","category":"Nova,OpenStack"},{"title":"跨Cell场景下查询的那些事儿","link":"http://yikun.github.io/2017/11/16/跨Cell场景下查询的那些事儿/","description":"1. 背景我们知道Nova目前正在慢慢地演进到Cell V2架构，Cell V2架构中，很重要的一个变化就是数据库的拆分，清晰的划分了数据库的职能，从而有具备横向扩展的能力。顶层数据库(nova_api)用来存储全局数据，而Cell中的数据库(nova_cellX)仅存储计算节点相关的数据。比如，创建虚拟机的全局数据，比如Flavor、Keypair之类的数据，放在上层的nova_api数据库中，而虚拟机本身的信息，比如某个虚拟机的信息，放在了子Cell中。 这样的架构另一个好处是Cell很轻松的可以实现扩展，从而提升虚拟机数量的规模。然而，这引入了一个问题，就是没有一个地方存储着全量虚拟机的数据了。当我们需要一些全局的虚拟机数据查询时（比如查询全量虚拟机列表）就比较棘手了。","pubDate":"Thu, 16 Nov 2017 13:19:14 GMT","guid":"http://yikun.github.io/2017/11/16/跨Cell场景下查询的那些事儿/","category":"Nova,OpenStack"},{"title":"[译] An Update on the Placement API and Scheduler plans for Queens","link":"http://yikun.github.io/2017/10/25/译-An-Update-on-the-Placement-API-and-Scheduler-plans-for-Queens/","description":"原文链接：https://github.com/jaypipes/articles/blob/master/openstack/placement-queens-update.md 这篇文章主要讲了在过去几个版本中，OpenStack社区对于Nova调度及Placement服务相关工作的更新进展。我也会着重介绍一些我们在Q版本中主要处理的几个BP，同时也介绍了未来重点工作的路标，我们会在未来的几个release中完成它们。","pubDate":"Wed, 25 Oct 2017 06:10:07 GMT","guid":"http://yikun.github.io/2017/10/25/译-An-Update-on-the-Placement-API-and-Scheduler-plans-for-Queens/","category":"Nova,OpenStack"},{"title":"OpenStack Nova虚拟机冷迁移流程解析","link":"http://yikun.github.io/2017/10/11/OpenStack-Nova虚拟机冷迁移流程解析/","description":"1. 概述虚拟机冷迁移由于当用户想把虚拟机从一个计算节点移动到其他节点。主要涉及的命令如下：12$ nova migrate server_id$ nova resize-confirm server_id 看到后是不是觉得有点奇怪为啥migrate之后，还要resize-confirm？resize操作其实和migrate操作比较类似，不同的是迁移前后的flavor不一样。一般情况下resize的场景是，对虚拟机进行扩容，把flavor调大之类的。所以，在代码级别，nova也将两个流程合一了。migrate就是一个没有flavor变化的resize。","pubDate":"Wed, 11 Oct 2017 08:36:09 GMT","guid":"http://yikun.github.io/2017/10/11/OpenStack-Nova虚拟机冷迁移流程解析/","category":"Nova,OpenStack"},{"title":"OpenStack Nova虚拟机创建流程解析","link":"http://yikun.github.io/2017/09/27/OpenStack-Nova虚拟机创建流程解析/","description":"1. 概述Nova是OpenStack中处理计算业务（虚拟机、裸机、容器）的组件，整体的虚拟机创建流程自然是学习和熟悉Nova组件的第一步。本篇文章主要基于OpenStack Pike版本，基于最新的Cell v2架构部署为例，来介绍虚拟机的创建流程，并分析了Pike等最近几个版本中，虚拟机创建流程的关键变化。","pubDate":"Wed, 27 Sep 2017 03:15:15 GMT","guid":"http://yikun.github.io/2017/09/27/OpenStack-Nova虚拟机创建流程解析/","category":"Nova,OpenStack"},{"title":"[译] Simpler Road to Cinder Active-Active","link":"http://yikun.github.io/2017/08/16/译-Simpler-Road-to-Cinder-Active-Active/","description":"译注：本篇文章为作者介绍Cinder AA方案的文章，作者是gorka，是实现cinder AA BP的core，文章介绍了这哥们实现AA时的记录，算是对方案的一种解释以及设计思路的总结，核心思想为以下几点： 每个volume node都增加一个cluster的配置项，作为集群，标记这个节点属于某个集群； 通过cluster@backend作为消息队列的topic，并且启动cluster@backend的服务； scheduler进行调度时，投递到某个合适的集群，集群中的某个后端进行消费； 消费时，将操作记录在worker中，用来标记这个资源由某个worker来操作，这样当发生异常时，可以确保仅有某个worker进行cleanup的操作。 原文链接：Simpler Road to Cinder Active-Active","pubDate":"Wed, 16 Aug 2017 12:50:32 GMT","guid":"http://yikun.github.io/2017/08/16/译-Simpler-Road-to-Cinder-Active-Active/","category":"OpenStack,Cinder"},{"title":"一次有关OpenStack请求的性能问题分析","link":"http://yikun.github.io/2016/07/22/一次有关OpenStack请求的性能问题分析/","description":"0. 背景介绍目前OpenStack对外提供的北向接口是以REST接口提供的，也就是说通过HTTP（HTTPS）接口进行请求，进行虚拟机或者卷等相关的操作。OpenStack提供I层基本的能力，比如创建、查询、删除虚拟机或者卷等操作，以OpenStack作为平台，对上提供用户接口，对下操作下层Driver完成对设备的操作，其大致的架构基本如下所示：","pubDate":"Fri, 22 Jul 2016 15:09:25 GMT","guid":"http://yikun.github.io/2016/07/22/一次有关OpenStack请求的性能问题分析/","category":"OpenStack"},{"title":"一致性哈希算法的理解与实践","link":"http://yikun.github.io/2016/06/09/一致性哈希算法的理解与实践/","description":"0. 概述在维基百科中，是这么定义的 一致哈希是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n个关键字重新映射，其中K是关键字的数量， n是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。 1. 引出 我们在上文中已经介绍了一致性Hash算法的基本优势，我们看到了该算法主要解决的问题是：当slot数发生变化时，能够尽量少的移动数据。那么，我们思考一下，普通的Hash算法是如何实现？又存在什么问题呢？那么我们引出一个问题： 假设有1000w个数据项，100个存储节点，请设计一种算法合理地将他们存储在这些节点上。 看一看普通Hash算法的原理：","pubDate":"Thu, 09 Jun 2016 02:43:54 GMT","guid":"http://yikun.github.io/2016/06/09/一致性哈希算法的理解与实践/","category":"系统"},{"title":"理解Python中的“with”","link":"http://yikun.github.io/2016/04/15/理解Python中的“with”/","description":"1. 缘起Python中，打开文件的操作是非常常见的，也是非常方便的，那么如何优雅的打开一个文件？大部分的同学会这样实现： 12with open( \"a.txt\" ) as f : # do something 大家都知道，这样写可以自动处理资源的释放、处理异常等，化简了我们打开文件的操作，那么，with到底做了什么呢？","pubDate":"Fri, 15 Apr 2016 15:44:15 GMT","guid":"http://yikun.github.io/2016/04/15/理解Python中的“with”/","category":"Python"},{"title":"存储数据包的一生","link":"http://yikun.github.io/2016/04/03/存储数据包的一生/","description":"最近认认真真学习了一个叫《Life of a Storage Packet》讲座，借助这个讲座将整个存储的过程理解了下，不放过任何一个有疑问的点。这篇文章算是对讲座的理解和自己收获的总结，同时也为那些对存储系统不够了解又想要了解的初学者，展现一个存储数据包的“生命”。这个演讲主要聚焦在“整体的存储”，强调存储系统中各个基本元素的关系，并且尽可能简单、清楚地用一种不同的方式可视化一些存储的概念。 先上一张大图，可以说这篇文章目的就是解释这个图：","pubDate":"Sun, 03 Apr 2016 14:04:23 GMT","guid":"http://yikun.github.io/2016/04/03/存储数据包的一生/","category":"系统"},{"title":"OpenStack源码分析-Cinder中的调度机制","link":"http://yikun.github.io/2016/03/05/OpenStack源码分析-Cinder中的调度机制/","description":"整理了一下目前cinder中支持的调度的Filter和Weigher：后面结合源码看下实现，留坑~","pubDate":"Fri, 04 Mar 2016 16:45:44 GMT","guid":"http://yikun.github.io/2016/03/05/OpenStack源码分析-Cinder中的调度机制/","category":"Cinder"},{"title":"OpenStack源码分析-Service启动流程","link":"http://yikun.github.io/2016/03/05/OpenStack源码分析-Service启动流程/","description":"","pubDate":"Fri, 04 Mar 2016 16:38:21 GMT","guid":"http://yikun.github.io/2016/03/05/OpenStack源码分析-Service启动流程/","category":"OpenStack,Cinder"},{"title":"OpenStack源码分析-挂载卷流程","link":"http://yikun.github.io/2016/03/05/OpenStack源码分析-挂载卷流程/","description":"1. 挂卷流程 当Nova volume-attach server volume执行后，主要经过以下几步：a. Nova Client解析指令，通过RESTFUL接口访问nova-api；b. Nova API解析响应请求获取虚拟机的基本信息，然后向cinder-api发出请求保留，并向nova-compute发送RPC异步调用请求卷挂载；c. Nova-compute向cinder-api初始化信息，并根据初始化连接调用Libvirt的接口完成挂卷流程；d. 进而调用cinder-volume获取连接，获取了连接后，通过RESTFUL请求cinder-api进行数据库更新操作。","pubDate":"Fri, 04 Mar 2016 16:32:58 GMT","guid":"http://yikun.github.io/2016/03/05/OpenStack源码分析-挂载卷流程/","category":"Cinder"},{"title":"优雅地调试OpenStack","link":"http://yikun.github.io/2016/02/23/优雅地调试OpenStack/","description":"恩，题目首先要起的高逼格一些。2333。 在前面学习代码的过程中，主要通过源码来学习，开始学起来确实有点费劲，因为欠缺对OpenStack的整体的意识，于是搭建OpenStack开发环境对OpenStack的运行环境和使用有了初步认知。也看到了启动OpenStack后的一些相关进程，那么这些进程是如何与源码对应起来的呢？如何去调试OpenStack呢？本篇文章就讲下我的探索。","pubDate":"Mon, 22 Feb 2016 16:00:52 GMT","guid":"http://yikun.github.io/2016/02/23/优雅地调试OpenStack/","category":"OpenStack"},{"title":"OpenStack源码分析-Cinder删除卷流程","link":"http://yikun.github.io/2016/02/21/OpenStack源码分析-Cinder删除卷流程/","description":"1. Cinder删除卷整体流程 删除卷流程比较简单，主要就是cinder-api解析Cilent的指令，并响应，发送RPC调用cinder-volume的delete操作，详细流程如下：a. Client发送删除指令，通过RESTful接口访问cinder-api；b. Cinder-api解析响应请求，通过RPC调用cinder-volume；c. Cinder-volume通过调用Driver的delete函数进行删除。 2. 源码详解 2.1 Cinder API(1) Cinder\\api\\v2\\volumes.pyVolumeController的delete函数响应请求，首先从API获取Volume对象信息，然后，调用API的delete对对象进行删除；(2) Cinder\\volume\\api.pyAPI.delete的对卷的状态进行检查，并更新状态为“deleting”，然后调用rpcapi的delete_volume函数 2.2 Cinder Volume(1) Cinder\\volume\\rpcapi.pyVolumeAPI函数投递一个远程消息，通过消息队列远程调用cinder volume的delete_volume函数。(2) Cinder\\volume\\manager最终通过VolumeManager调用dirver的delete_volume对卷进行删除。","pubDate":"Sun, 21 Feb 2016 11:56:59 GMT","guid":"http://yikun.github.io/2016/02/21/OpenStack源码分析-Cinder删除卷流程/","category":"OpenStack,Cinder"},{"title":"OpenStack源码分析-Cinder创建卷流程","link":"http://yikun.github.io/2016/02/14/OpenStack源码分析-Cinder创建卷流程/","description":"1. Cinder创卷整体流程 如整体架构图所示，创建卷涉及的答题步骤主要有以下几步：a. Client发送请求，通过RESTFUL接口访问cinder-api。b. Api解析响应请求，api解析由Client发送来的请求，并通过rpc进一步调用cinder-scheduler。c. Scheduler对资源进行调度，scheduler选择合适的节点进行。d. Volume调用Driver创建卷，volume通过指定Driver进行卷的创建。 2. 源码详解代码的整体流程如下所示： 从上图可以看出，整体处理流程包括三大部分，分别是API、Scheduler、Volume三部分。 2.1 Cinder API部分 (1) cinder\\api\\v2\\volumes.pyVolumeController. create函数对创建请求进行响应，首先函数对volume_type、metadata、snapshot等信息进行检查，然后调用Volume API的create进行创建。(2) cinder\\volume\\api.pyAPI.create函数对source_volume、volume_type等参数进行进一步检查，并调用cinder.volume.flows.api.get_flow来创建。(3) cinder\\volume\\flows\\api\\create_volume.pyget_flow函数检查Quata，最后创建EntryCreateTask及VolumeCastTask等任务，其中EntryCreateTask会将卷的创建过程写入数据库，此时卷的状态为”creating”。VolumeCastTask.excute函数会调用VoumeCastTask._cast_create_volumeVolumeCastTask._cast_create_volume函数，如果未传入host，则会经过调度进行创建卷，通过scheduler_rpcapi.create_volume创建卷；如果未传入host则直接交由Volume Manager去创建卷。 至此为止，Cinder API部分完成了自己的工作。 2.2 Cinder Scheduler (1) cinder\\scheduler\\rpcapi.py（此步还属于cinder-api）SchedulerAPI.create_volume函数会通过消息异步调用SchedulerManager.create_volume函数。(2) cinder\\scheduler\\manager.pySchedulerManager.create_volume函数，使用自己的flow来创建volume，其中还传入了Driver。(3) cinder\\scheduler\\flows\\create_volume.pyget_flow函数，创建ScheduleCreateVolumeTaskScheduleCreateVolumeTask.execute函数，会调用driver_api.schedule_create_volume(4) cinder\\scheduler\\filter_scheduler.pyFilterScheduler. schedule_create_volume函数，更新数据库，最后通过消息队列请求调用volume_rpcapi.create_volume。 2.3 Cinder Volume (1) /cinder/volume/rpcapi.py（此步还属于cinder-scheduler）VolumeAPI.create_volume会通过消息队列远程调用VolumeManager.create_volume(2) /cinder/volume/manager.pyVolumeManager函数也使用flow来创建volume，执行CreateVolumeFromSpecTask这个任务(3) /cinder/volume/flows/manager/create_volume.pyCreateVolumeFromSpecTask.excute，这个函数会根据创建的不同类别，去创建卷，例如调用create_raw_volume，最终会调用具体的driver进行卷的创建。在完成创卷后，CreateVolumeOnFinishTask这个任务，启动更新数据库，将卷更新为available状态。 我们可以看到在创建卷的过程中盘的状态会从“creating”状态变为“available”状态。","pubDate":"Sun, 14 Feb 2016 09:43:30 GMT","guid":"http://yikun.github.io/2016/02/14/OpenStack源码分析-Cinder创建卷流程/","category":"OpenStack,Cinder"},{"title":"搭建OpenStack开发环境","link":"http://yikun.github.io/2016/02/10/搭建OpenStack开发环境/","description":"前段时间主要了解了一些OpenStack相关的基础性东西，现在希望通过安装使用来增强一下对系统整体的认识，最近也读了一篇文章如何学习开源项目，基本和我的想法很类似，所以基本上也就是按照这个节奏来的。不说废话了，开始。","pubDate":"Tue, 09 Feb 2016 16:10:09 GMT","guid":"http://yikun.github.io/2016/02/10/搭建OpenStack开发环境/","category":"OpenStack"},{"title":"存储知识学习","link":"http://yikun.github.io/2016/02/03/存储知识学习/","description":"1. 磁盘基本知识磁盘大致由盘片、磁头、步进电机等几部分组成组成。盘面：硬盘一般含有一个或多个盘片，一个盘片包含两个盘面。磁道：每个盘面被划成多个狭窄的同心圆环，这样的圆环叫做磁道。扇区：每个磁道的每段圆弧叫做一个扇区，是读写的最小单位。柱面：所有盘面上的同一磁道，在竖直方向构成一个圆柱，称为柱面。 读写过程：硬盘读取数据时，磁头先移动到读取扇区所在磁道的上方，这个过程耗时叫做磁盘寻道时间，平均时间为10ms。之后，通过盘片的旋转，使得扇区转到磁头的下方，这个过程耗时叫做旋转延迟时间，对于7200转/min的硬盘转一周为60*1000/7200=8.33ms，平均旋转延迟为4.17ms（半圈）。 2. RAID基本知识RAID（Redundant Array of Independent Disks），即由独立的磁盘组成的具有冗余特性的阵列。其基本思想就是把多个相对便宜的硬盘组合起来，成为一个硬盘阵列组，使性能达到甚至超过一个价格昂贵、 容量巨大的硬盘。RAID 0，条带化存储，容量增加，并行化，但无冗余，容易单点故障。 RAID 1，镜像存储，写入速率慢，读取速率快，有冗余备份，优点是高可靠、高可用，缺点是高花费。 RAID 2，RAID 0的改进版，使用汉明码进行检测和纠错，适用于连续IO、大块IO（如视频流）。 RAID 3，RAID 3和RAID 2的思路比较相似，使用奇偶校验进行错误检测和纠错，但校验盘单点故障。 RAID 4，RAID 4和RAID 3思路一样，只不过是使用BLOCK进行存储。 RAID 5，校验信息交叉的存储在所有数据盘上，高冗余，高数据传输率，实现复杂。 RAID 6，相比RAID5增加块内的校验，允许同时坏2块硬盘而不丢失数据。 RAID 01，先做条带（0），再做镜像（1）。读写速度快，数据保护能力强，空间利用率50%。RAID 10，先做镜像（1），再做条带（0）。 3. 存储方式根据网上的资料和理解，用Visio整理了一张图对比了下几种方式： DAS全称为Direct Attached Storage，即服务器直连存储。如图所示，文件系统直接通过RAID完成对硬件访问。优点是操作简便，经济，缺点是分散式存储，不可集中管理。NAS全称为Network Attached Storage，即网络存储服务。如图所示，文件系统通过网络暴露出来给应用服务。优点是结构简单。配置使用管理非常方便，可实现跨平台的数据共享。缺点是需要占用网络资源、应用局限性大。SAN全称为Storage Aera Network，即存储区域网络，如图所示，RAID接口通过网络暴露出来。优点是扩展性强，集中管理，缺点是成本较高，管理维护难度大。 4. IP SAN与FC SANFC SAN指基于光纤通道（Fiber Channel）的存储区域网，在FC SAN中存在两张网，一张面向应用的网（IP网），另一张中则是存储网（FC网）。而IP SAN的出现则是为了寻求一种新的方式，用与应用网相同的体系架构来构造存储网，使用通用的IP网络及设备。FC SAN性能好，价格高，但与主流的IP网络异构。适用于关键应用的几种存储、备份及容灾。IP SAN则由于以太网MTU（1518字节）的限制，性能稍差，但基于通用的IP协议。适用于异地间的数据交换、备份容灾，非关键应用的集中存储。 5. LVM基本知识LVM的全称是Logical Volume Manager，逻辑卷轴管理，主要解决的问题是，弹性调整文件系统的容量。 与传统的磁盘与分区相比，LVM为计算机提供了更高层次的存储，通过在磁盘分区和文件系统之间增加一个逻辑层，提供一个抽象的逻辑盘卷。 参考资料 《大话存储》 RAID技术介绍和总结http://blog.jobbole.com/83808/ 基于OpenStack的NAS服务https://www.ustack.com/blog/openstack-nas/","pubDate":"Wed, 03 Feb 2016 14:46:58 GMT","guid":"http://yikun.github.io/2016/02/03/存储知识学习/","category":"OpenStack,Cinder"},{"title":"[译]Internationalization","link":"http://yikun.github.io/2016/01/23/译-Internationalization/","description":"Nova uses the oslo.i18n library to support internationalization. The oslo.i18n library is built on top of gettext and provides functions that are used to enable user-facing strings such as log messages to appear in the appropriate language in different locales. Nova exposes the oslo.i18n library support via the nova/i18n.py integration module. This module provides the functions needed to wrap translatable strings. It provides the _() wrapper for general user-facing messages and specific wrappers for messages used only for logging. DEBUG level messages do not need translation but CRITICAL, ERROR, WARNING and INFO messages should be wrapped with _LC(), _LE(), _LW() or _LI() respectively. 理解：Nova是通过oslo.i18n来支持国际化的，oslo.i18n是基于getnext做的，这个库可以把面向用户的字符（比如日志）翻译成指定的语言。其中DEBUG信息不翻译，其他的信息会被翻译。 比如： 1234567# debug logLOG.debug(\"block_device_mapping %(mapping)s\", &#123;'mapping': block_device_mapping&#125;)# warn logLOG.warn(_LW('Unknown base file %(img)s'), &#123;'img': img&#125;)# not lograise nova.SomeException(_('Invalid service catalogue')) Do not use locals() for formatting messages because: 1. It is not as clear as using explicit dicts. 2. It could produce hidden errors during refactoring. 3. Changing the name of a variable causes a change in the message. 4. It creates a lot of otherwise unused variables. If you do not follow the project conventions, your code may cause hacking checks to fail. 另外，文中提到了不要使用locals()去格式化消息主要4点原因：1.不清楚是否有关键字. 2.重构时会有潜在的出错可能. 3.变量名变了消息就变. 4.创建很多无用的变量。 这些函数_(), _LC(), _LE(), _LW() and _LI()可以通过以下方法导入： 12345from nova.i18n import _from nova.i18n import _LCfrom nova.i18n import _LEfrom nova.i18n import _LWfrom nova.i18n import _LI","pubDate":"Fri, 22 Jan 2016 16:43:37 GMT","guid":"http://yikun.github.io/2016/01/23/译-Internationalization/","category":"Nova"},{"title":"[译]Virtual Machine States and Transitions","link":"http://yikun.github.io/2016/01/20/译-Virtual-Machine-States-and-Transitions/","description":"虚拟机的状态及其转移，主要讲了一些虚拟机的状态以及在创建虚拟机时的状态转移情况，目前理解不够深刻，需要在后面看代码时，进一步深入理解。","pubDate":"Wed, 20 Jan 2016 15:46:59 GMT","guid":"http://yikun.github.io/2016/01/20/译-Virtual-Machine-States-and-Transitions/","category":"Nova"},{"title":"2015，再见","link":"http://yikun.github.io/2016/01/02/2015，再见/","description":"2015年是很特殊的一年，是长达快20年的学生时代的终结。从年初最开始的时候，就对今年的会发生的事情做好了准备，也基本上按照自己的想法发生了。之前，也有一些计划，基本达到预期，现在想起这些目标都算是一些学生时代的梦想吧，这篇总结也大致的从这些方面展开。","pubDate":"Fri, 01 Jan 2016 16:05:42 GMT","guid":"http://yikun.github.io/2016/01/02/2015，再见/","category":"随笔"},{"title":"Python3源码学习-整型","link":"http://yikun.github.io/2015/12/21/Python3源码学习-整型/","description":"1. 引入我们先看看对整型变量i进行赋值，并对i进行显示的过程： 123&gt;&gt;&gt; i=1&gt;&gt;&gt; i1","pubDate":"Mon, 21 Dec 2015 13:48:29 GMT","guid":"http://yikun.github.io/2015/12/21/Python3源码学习-整型/","category":"Python"},{"title":"Python3源码学习-类型","link":"http://yikun.github.io/2015/12/20/Python3源码学习-类型/","description":"1. 类型我们在《Python3源码学习-对象》中提到了每个对象都含有一个type的属性，我们看看type是个什么东西，目光移到object.h： 1234567891011121314151617181920typedef struct _typeobject &#123; PyObject_VAR_HEAD const char *tp_name; /* For printing, in format \"&lt;module&gt;.&lt;name&gt;\" */ Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */ /* Methods to implement standard operations */ destructor tp_dealloc; //... ... /* More standard operations (here for binary compatibility) */ hashfunc tp_hash; ternaryfunc tp_call; reprfunc tp_str; getattrofunc tp_getattro; setattrofunc tp_setattro; //... ...&#125; PyTypeObject;","pubDate":"Sun, 20 Dec 2015 15:03:21 GMT","guid":"http://yikun.github.io/2015/12/20/Python3源码学习-类型/","category":"Python"}]}